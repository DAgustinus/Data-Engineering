# Summary
### The README file includes a summary of the project, how to run the Python scripts, and an explanation of the files in the repository

Thank you for spending the time to take a look at the README.md file!

#### This readme file will go through:
1. the files within this projects
2. the available Python scripts
3. how to run the scripts
4. Overview of the "AWS ETL Rundown.ipynb file"
    
This project is based on the Udacity Data Engineering course and it teaches the student to perform an ETL within AWS and automating it by using Python.

#### In this project, we have:
1. One Python Notebook 
2. Three Python files
3. Config file which is used to get all of the proper data dwh.cfg
    
The two Python Notebooks are used to test the ETL as well as to run SQL test to ensure that the data are inside of the tables that we have created. As for the three Python files, they are used to create the necessary tables, store all of the SQL queries, as well as the main ETL process. Last but not least, the Data folder, consists of layers of data that is stored in CSV.

To start seeing the results, go ahead and follow the steps below:
1. Create your cluster by following the "AWS ETL Rundown.ipynb file" from step 0 - 2.
2. Run create_tables.py and run etl.py to run the data ingestion process. All of the data are coming from the S3 which is configured within the dwh.cfg file as for now.
    

Thanks for checking it out!

*Dan Agustinus*
