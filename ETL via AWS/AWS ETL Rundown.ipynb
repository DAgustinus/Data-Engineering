{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running ETL within AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Daniel Agustinus Pesiwarissa\n",
    "\n",
    "Within this Python notebook,I will show you how an ETL can be performed within AWS:\n",
    "- Creating the Redshift Cluster\n",
    "- Setting up the IAM role ARN that would give access to Redshift to read from S3\n",
    "- Create the Staging table and the Production tables\n",
    "- Load the data from Udacity's S3 to the Staging table, then load it to the production. This can also be considered as an ELT instead of an ETL\n",
    "- Perform analytical query on the IPYNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import configparser\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've imported several libraries to ensure that we can perform the necessary tasks\n",
    "- Configparser is used to read configuration setup information straight from the .cfg file. By doing this, we will not touch the source code at all\n",
    "- The matplotlib and pandas is used for the analytical portion for the latter stage\n",
    "- The %load_ext sql is used so we can perform SQL queries within this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "KEY                    = config.get('AWS','KEY')\n",
    "SECRET                 = config.get('AWS','SECRET')\n",
    "\n",
    "DWH_CLUSTER_TYPE       = config.get(\"CLUSTER\",\"DWH_CLUSTER_TYPE\")\n",
    "DWH_NUM_NODES          = config.get(\"CLUSTER\",\"DWH_NUM_NODES\")\n",
    "DWH_NODE_TYPE          = config.get(\"CLUSTER\",\"DWH_NODE_TYPE\")\n",
    "\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")\n",
    "DWH_DB                 = config.get(\"CLUSTER\",\"DB_NAME\")\n",
    "DWH_DB_USER            = config.get(\"CLUSTER\",\"DB_USER\")\n",
    "DWH_DB_PASSWORD        = config.get(\"CLUSTER\",\"DB_PASSWORD\")\n",
    "DWH_PORT               = config.get(\"CLUSTER\",\"DB_PORT\")\n",
    "\n",
    "DWH_IAM_ROLE_NAME      = config.get(\"DWH\", \"DWH_IAM_ROLE_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 0: Create clients for IAM, EC2, S3 and Redshift\n",
    "\n",
    "Within the code below, we will be starting the connection to the EC2, S3, IAM, and the Redshift it self. We will need to be able to connect to all of the above so we can run everything properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2 = boto3.resource('ec2',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                    )\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                   )\n",
    "\n",
    "iam = boto3.client('iam',aws_access_key_id=KEY,\n",
    "                     aws_secret_access_key=SECRET,\n",
    "                     region_name='us-west-2'\n",
    "                  )\n",
    "\n",
    "redshift = boto3.client('redshift',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: IAM ROLE\n",
    "- Create an IAM Role that makes Redshift able to access S3 bucket (ReadOnly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 Creating a new IAM Role\n",
      "An error occurred (EntityAlreadyExists) when calling the CreateRole operation: Role with name dwhRole already exists.\n",
      "1.2 Attaching Policy\n",
      "1.3 Get the IAM role ARN\n",
      "arn:aws:iam::692420999420:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "#1.1 Create the role, \n",
    "try:\n",
    "    print(\"1.1 Creating a new IAM Role\") \n",
    "    dwhRole = iam.create_role(\n",
    "        Path='/',\n",
    "        RoleName=DWH_IAM_ROLE_NAME,\n",
    "        Description = \"Allows Redshift clusters to call AWS services on your behalf.\",\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {'Statement': [{'Action': 'sts:AssumeRole',\n",
    "               'Effect': 'Allow',\n",
    "               'Principal': {'Service': 'redshift.amazonaws.com'}}],\n",
    "             'Version': '2012-10-17'})\n",
    "    )    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "    \n",
    "print(\"1.2 Attaching Policy\")\n",
    "\n",
    "iam.attach_role_policy(RoleName=DWH_IAM_ROLE_NAME,\n",
    "                       PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    "                      )['ResponseMetadata']['HTTPStatusCode']\n",
    "\n",
    "print(\"1.3 Get the IAM role ARN\")\n",
    "roleArn = iam.get_role(RoleName=DWH_IAM_ROLE_NAME)['Role']['Arn']\n",
    "\n",
    "print(roleArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2:  Redshift Cluster\n",
    "\n",
    "- Create a RedShift Cluster\n",
    "- For complete arguments to `create_cluster`, see [docs](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/redshift.html#Redshift.Client.create_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = redshift.create_cluster( \n",
    "        ClusterType=DWH_CLUSTER_TYPE,\n",
    "        NodeType=DWH_NODE_TYPE,\n",
    "        NumberOfNodes=int(DWH_NUM_NODES),\n",
    "        DBName=DWH_DB,\n",
    "        ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,\n",
    "        MasterUsername=DWH_DB_USER,\n",
    "        MasterUserPassword=DWH_DB_PASSWORD,\n",
    "        IamRoles=[roleArn]\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be saving the Host address and the ROLE within the DWH_ENDPOINT and DWH_ROLE_ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettyRedshiftProps(props):\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    keysToShow = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\", \"MasterUsername\", \"DBName\", \"Endpoint\", \"NumberOfNodes\", 'VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)\n",
    "\n",
    "DWH_ENDPOINT = myClusterProps['Endpoint']['Address']\n",
    "DWH_ROLE_ARN = myClusterProps['IamRoles'][0]['IamRoleArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Open an incoming  TCP port to access the cluster ednpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-79f6ac37')\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vpc = ec2.Vpc(id=myClusterProps['VpcId'])\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName=defaultSg.group_name,\n",
    "        CidrIp='0.0.0.0/0',\n",
    "        IpProtocol='TCP',\n",
    "        FromPort=int(DWH_PORT),\n",
    "        ToPort=int(DWH_PORT)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if we're connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://dagustinus:IcePack310@redshift-cluster-1.cplfbl78n5jd.us-west-2.redshift.amazonaws.com:5439/dwh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Connected: dagustinus@dwh'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, 'redshift-cluster-1.cplfbl78n5jd.us-west-2.redshift.amazonaws.com', DWH_PORT,DWH_DB)\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Creating the Staging and Production tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables has been dropped.\n",
      "All tables has been created.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from sql_queries import create_table_queries, drop_table_queries\n",
    "\n",
    "conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(DWH_ENDPOINT, DWH_DB, DWH_DB_USER, DWH_DB_PASSWORD, DWH_PORT))\n",
    "cur = conn.cursor()\n",
    "\n",
    "for query in drop_table_queries:\n",
    "    cur.execute(query)\n",
    "    conn.commit()\n",
    "print('Tables has been dropped.')\n",
    "\n",
    "for query in create_table_queries:\n",
    "    cur.execute(query)\n",
    "    conn.commit()\n",
    "print('All tables has been created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Loading the data to the Staging, then to Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sql_queries import copy_table_queries, insert_table_queries\n",
    "\n",
    "for query in copy_table_queries:\n",
    "    cur.execute(query)\n",
    "    conn.commit()\n",
    "\n",
    "for query in insert_table_queries:\n",
    "    cur.execute(query)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Performing analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://dagustinus:IcePack310@redshift-cluster-1.cplfbl78n5jd.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      " * postgresql://dagustinus:***@redshift-cluster-1.cplfbl78n5jd.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>artist name</th>\n",
       "        <th>played</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Dwight Yoakam</td>\n",
       "        <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Kid Cudi / Kanye West / Common</td>\n",
       "        <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Kid Cudi</td>\n",
       "        <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Ron Carter</td>\n",
       "        <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Lonnie Gordon</td>\n",
       "        <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>B.o.B</td>\n",
       "        <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Usher</td>\n",
       "        <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Usher featuring Jermaine Dupri</td>\n",
       "        <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Muse</td>\n",
       "        <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Richard Hawley And Death Ramps_ Arctic Monkeys</td>\n",
       "        <td>5</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('Dwight Yoakam', 37),\n",
       " ('Kid Cudi / Kanye West / Common', 10),\n",
       " ('Kid Cudi', 10),\n",
       " ('Ron Carter', 9),\n",
       " ('Lonnie Gordon', 9),\n",
       " ('B.o.B', 8),\n",
       " ('Usher', 6),\n",
       " ('Usher featuring Jermaine Dupri', 6),\n",
       " ('Muse', 6),\n",
       " ('Richard Hawley And Death Ramps_ Arctic Monkeys', 5)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT,DWH_DB)\n",
    "print(conn_string)\n",
    "\n",
    "%sql $conn_string\n",
    "\n",
    "Top_10_Artist = \"\"\"\n",
    "select a.name as \"Artist Name\", count(s.artist_id) as played\n",
    "from songplays s\n",
    "join artists a on s.artist_id = a.artist_id\n",
    "group by a.name \n",
    "order by played desc\n",
    "limit 10;\n",
    "\"\"\"\n",
    "\n",
    "%sql $Top_10_Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dagustinus:***@redshift-cluster-1.cplfbl78n5jd.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>song title</th>\n",
       "        <th>artist</th>\n",
       "        <th>played</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>You&#x27;re The One</td>\n",
       "        <td>Dwight Yoakam</td>\n",
       "        <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Catch You Baby (Steve Pitron &amp; Max Sanna Radio Edit)</td>\n",
       "        <td>Lonnie Gordon</td>\n",
       "        <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>I CAN&#x27;T GET STARTED</td>\n",
       "        <td>Ron Carter</td>\n",
       "        <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Nothin&#x27; On You [feat. Bruno Mars] (Album Version)</td>\n",
       "        <td>B.o.B</td>\n",
       "        <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Hey Daddy (Daddy&#x27;s Home)</td>\n",
       "        <td>Usher featuring Jermaine Dupri</td>\n",
       "        <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Hey Daddy (Daddy&#x27;s Home)</td>\n",
       "        <td>Usher</td>\n",
       "        <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Up Up &amp; Away</td>\n",
       "        <td>Kid Cudi</td>\n",
       "        <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Make Her Say</td>\n",
       "        <td>Kid Cudi / Kanye West / Common</td>\n",
       "        <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Up Up &amp; Away</td>\n",
       "        <td>Kid Cudi / Kanye West / Common</td>\n",
       "        <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Make Her Say</td>\n",
       "        <td>Kid Cudi</td>\n",
       "        <td>5</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(\"You're The One\", 'Dwight Yoakam', 37),\n",
       " ('Catch You Baby (Steve Pitron & Max Sanna Radio Edit)', 'Lonnie Gordon', 9),\n",
       " (\"I CAN'T GET STARTED\", 'Ron Carter', 9),\n",
       " (\"Nothin' On You [feat. Bruno Mars] (Album Version)\", 'B.o.B', 8),\n",
       " (\"Hey Daddy (Daddy's Home)\", 'Usher featuring Jermaine Dupri', 6),\n",
       " (\"Hey Daddy (Daddy's Home)\", 'Usher', 6),\n",
       " ('Up Up & Away', 'Kid Cudi', 5),\n",
       " ('Make Her Say', 'Kid Cudi / Kanye West / Common', 5),\n",
       " ('Up Up & Away', 'Kid Cudi / Kanye West / Common', 5),\n",
       " ('Make Her Say', 'Kid Cudi', 5)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_10_Songs=\"\"\"\n",
    "select s.title as \"Song Title\", a.name as \"Artist\", count(s.title) as played\n",
    "from songplays sp\n",
    "join songs s on sp.song_id = s.song_id\n",
    "join artists a on sp.artist_id = a.artist_id\n",
    "group by s.title,a.name\n",
    "order by played desc\n",
    "limit 10;\n",
    "\"\"\"\n",
    "\n",
    "%sql $Top_10_Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dagustinus:***@redshift-cluster-1.cplfbl78n5jd.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "2 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>level</th>\n",
       "        <th>total users per level</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>paid</td>\n",
       "        <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>free</td>\n",
       "        <td>83</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('paid', 22), ('free', 83)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Users_per_level=\"\"\"\n",
    "select level, count(level) as \"total users per level\"\n",
    "from users\n",
    "group by level\n",
    "\"\"\"\n",
    "\n",
    "%sql $Users_per_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 7: Clean up the Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cluster': {'ClusterIdentifier': 'redshift-cluster-1',\n",
       "  'NodeType': 'dc2.large',\n",
       "  'ClusterStatus': 'deleting',\n",
       "  'MasterUsername': 'dagustinus',\n",
       "  'DBName': 'dwh',\n",
       "  'Endpoint': {'Address': 'redshift-cluster-1.cplfbl78n5jd.us-west-2.redshift.amazonaws.com',\n",
       "   'Port': 5439},\n",
       "  'ClusterCreateTime': datetime.datetime(2019, 9, 12, 14, 15, 28, 251000, tzinfo=tzlocal()),\n",
       "  'AutomatedSnapshotRetentionPeriod': 1,\n",
       "  'ClusterSecurityGroups': [],\n",
       "  'VpcSecurityGroups': [{'VpcSecurityGroupId': 'sg-79f6ac37',\n",
       "    'Status': 'active'}],\n",
       "  'ClusterParameterGroups': [{'ParameterGroupName': 'default.redshift-1.0',\n",
       "    'ParameterApplyStatus': 'in-sync'}],\n",
       "  'ClusterSubnetGroupName': 'default',\n",
       "  'VpcId': 'vpc-5e2a9226',\n",
       "  'AvailabilityZone': 'us-west-2c',\n",
       "  'PreferredMaintenanceWindow': 'tue:08:30-tue:09:00',\n",
       "  'PendingModifiedValues': {},\n",
       "  'ClusterVersion': '1.0',\n",
       "  'AllowVersionUpgrade': True,\n",
       "  'NumberOfNodes': 4,\n",
       "  'PubliclyAccessible': True,\n",
       "  'Encrypted': False,\n",
       "  'Tags': [],\n",
       "  'EnhancedVpcRouting': False,\n",
       "  'IamRoles': [{'IamRoleArn': 'arn:aws:iam::692420999420:role/dwhRole',\n",
       "    'ApplyStatus': 'in-sync'}],\n",
       "  'MaintenanceTrackName': 'current'},\n",
       " 'ResponseMetadata': {'RequestId': 'c4f7a642-d568-11e9-ae86-c3ead02dc7ee',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'c4f7a642-d568-11e9-ae86-c3ead02dc7ee',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '2309',\n",
       "   'vary': 'Accept-Encoding',\n",
       "   'date': 'Thu, 12 Sep 2019 14:22:36 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### CAREFUL!!\n",
    "#-- Uncomment & run to delete the created resources\n",
    "redshift.delete_cluster( ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,  SkipFinalClusterSnapshot=True)\n",
    "#### CAREFUL!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 8: Turning off the IAM Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'cfa2aac5-d568-11e9-8bd8-6b3598217f12',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'cfa2aac5-d568-11e9-8bd8-6b3598217f12',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '200',\n",
       "   'date': 'Thu, 12 Sep 2019 14:22:54 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### CAREFUL!!\n",
    "#-- Uncomment & run to delete the created resources\n",
    "iam.detach_role_policy(RoleName=DWH_IAM_ROLE_NAME, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\n",
    "iam.delete_role(RoleName=DWH_IAM_ROLE_NAME)\n",
    "#### CAREFUL!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
